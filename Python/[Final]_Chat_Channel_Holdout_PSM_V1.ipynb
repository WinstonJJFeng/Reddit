{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This analysis is using the first day exposed users as cohort to evaluate how much impact Chat Channel product to Reddit users.\n"
      ],
      "metadata": {
        "id": "zN022r9zGPng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-bigquery\n",
        "!pip install psmpy\n",
        "# !pip install ace_tools\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Query large BQ table\n",
        "project_id = 'data-prod-165221'\n",
        "client = bigquery.Client(project=project_id)"
      ],
      "metadata": {
        "id": "kyH5TZ6PORwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525e5dd1-29fb-44f9-c90c-d7851ffce25e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.21.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.2.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.0)\n",
            "Requirement already satisfied: psmpy in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from psmpy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from psmpy) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from psmpy) (2.0.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from psmpy) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from psmpy) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from psmpy) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (4.52.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->psmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->psmpy) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->psmpy) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->psmpy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->psmpy) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->psmpy) (1.16.0)\n",
            "Authenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL"
      ],
      "metadata": {
        "id": "DgLmieRs9j0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        " SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `data-prod-165221.ds_v2_gold_tables.wjfeng_tmp_20240329_bets_chat_channels_holdout_exposed_users_step4`\n",
        "  WHERE 1=1\n",
        "    AND user_logged_in = 1\n",
        "    AND app_install = 1\n",
        "    AND (ios_l1 > 0 OR android_l1 > 0)\n",
        "\n",
        "'''\n",
        "df = client.query(sql).to_dataframe()\n",
        "\n",
        "\n",
        "sql = '''\n",
        "select * from `data-prod-165221.ds_v2_gold_tables.wjfeng_tmp_20240329_bets_chat_channels_holdout_tos`\n",
        "'''\n",
        "\n",
        "tos = client.query(sql).to_dataframe()"
      ],
      "metadata": {
        "id": "9ZVCr6_D9il6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('data frame size:')\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Create an OrdinalEncoder instance\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "df['geo_dummy'] = encoder.fit_transform(df[['geo']])\n",
        "\n",
        "\n",
        "# separate holdout and non-holdout group\n",
        "print(\"holdout group size\")\n",
        "df_holdout = df[(df['experiment_variant'] == 'holdout') & (df['is_cc_active'] == 0)]\n",
        "\n",
        "print(df_holdout.groupby('is_cc_active').size())\n",
        "\n",
        "df_treatment = df[(df['experiment_variant'] == 'control_1')]\n",
        "print(\"non-holdout group size\")\n",
        "print(df_treatment.groupby('is_cc_active').size())\n",
        "\n",
        "# release more RAM by deleting table no longer use\n",
        "del df\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "build a data frame including ony:\n",
        "[holdout] holdout group: non-Chat Channel active users\n",
        "[treatment] non-holdout group: Chat Channel active users ONLY\n",
        "\"\"\"\n",
        "df1 = df_treatment[df_treatment.is_cc_active==1]\n",
        "df0 = df_holdout[df_holdout.is_cc_active==0]\n",
        "frames = [df0, df1]\n",
        "df_prep = pd.concat(frames)\n",
        "print('df_prep size:')\n",
        "df_prep.shape\n",
        "\n",
        "\n",
        "# identifying two groups by assigning 0 or 1 to two group\n",
        "df_test = df_prep.copy()\n",
        "df_test['is_treatment'] = df_test['experiment_variant'].apply(lambda x: 0 if x == 'holdout' else 1)\n",
        "# df_test = df_test.drop(columns=['experiment_variant','first_exposure_timestamp','is_cc_active']) # without geo\n",
        "# df_test = df_test.drop(columns=['experiment_variant','first_exposure_timestamp','is_cc_active','geo'])\n",
        "df_test = df_test.drop(columns=['experiment_variant','first_exposure_timestamp','is_cc_active','geo'])\n",
        "df_test = df_test.fillna(0)\n",
        "\n",
        "from psmpy import PsmPy\n",
        "from psmpy.functions import cohenD\n",
        "import psmpy.plotting\n",
        "\n",
        "# Predict Propensity Scores\n",
        "psm = PsmPy(df_test, treatment='is_treatment', indx='user_id')\n",
        "psm.logistic_ps(balance = True)\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Add prediction column\n",
        "predicted_df = psm.predicted_data\n",
        "threshold = 0.5\n",
        "predicted_df['pred'] = np.where(predicted_df['propensity_score']>=threshold, 1, 0)\n",
        "\n",
        "# Assess the model\n",
        "print(f\"Accuracy: {np.mean(predicted_df['is_treatment']==predicted_df['pred']):.4f},\\\n",
        " ROC AUC: {roc_auc_score(predicted_df['is_treatment'], predicted_df['propensity_score']):.4f},\\\n",
        " F1-score: {f1_score(predicted_df['is_treatment'], predicted_df['pred']):.4f}\")\n",
        "\n",
        "# Visualise confusion matrix\n",
        "pd.crosstab(predicted_df['is_treatment'], predicted_df['pred']).rename(columns={0: False, 1:True})\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
        "\n",
        "# Visualise propensity\n",
        "sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==0], x='propensity_score', shade=True,\n",
        "            color='red', label='not_treatment_user', ax=ax[0])\n",
        "sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==1], x='propensity_score', shade=True,\n",
        "            color='blue', label='treatment_user', ax=ax[0])\n",
        "ax[0].set_title('Propensity')\n",
        "ax[0].legend(loc='center', bbox_to_anchor=(1.1, -0.3))\n",
        "\n",
        "\n",
        "# Visualise logit propensity\n",
        "sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==0], x='propensity_logit', shade=True,\n",
        "            color='red', label='not_treatment_user', ax=ax[1])\n",
        "sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==1], x='propensity_logit', shade=True,\n",
        "            color='blue', label='treatment_user', ax=ax[1])\n",
        "ax[1].set_title('Logit Propensity')\n",
        "ax[1].set_ylabel(\"\");\n",
        "\n",
        "\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import time\n",
        "# record the start time\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# Perform KNN Matching on Propensity Scores\n",
        "psm.predicted_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "psm.predicted_data.dropna(inplace=True)\n",
        "psm.knn_matched_12n(matcher='propensity_logit', how_many=1)\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JciNz91qFbDa",
        "outputId": "e8a5243b-c753-46e3-8ce5-00a716502d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data frame size:\n",
            "(224857, 21)\n",
            "holdout group size\n",
            "is_cc_active\n",
            "0    112279\n",
            "dtype: int64\n",
            "non-holdout group size\n",
            "is_cc_active\n",
            "0    111067\n",
            "1      1131\n",
            "dtype: int64\n",
            "df_prep size:\n",
            "Accuracy: 0.8285, ROC AUC: 0.8617, F1-score: 0.0870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5bc8d26d5cb3>:82: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==0], x='propensity_score', shade=True,\n",
            "<ipython-input-3-5bc8d26d5cb3>:84: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==1], x='propensity_score', shade=True,\n",
            "<ipython-input-3-5bc8d26d5cb3>:91: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==0], x='propensity_logit', shade=True,\n",
            "<ipython-input-3-5bc8d26d5cb3>:93: FutureWarning: \n",
            "\n",
            "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
            "This will become an error in seaborn v0.14.0; please update your code.\n",
            "\n",
            "  sns.kdeplot(data=predicted_df[predicted_df['is_treatment']==1], x='propensity_logit', shade=True,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Plot Propensity Scores\n",
        "psm.plot_match(Title='Side by side matched controls', Ylabel='Number of users', Xlabel= 'Propensity logit', names = ['treatment', 'control'], save=True)"
      ],
      "metadata": {
        "id": "BjG6rc3oShtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Matched IDs Table (Optional)\n",
        "print(\"View Matched IDs Table:\")\n",
        "print(psm.matched_ids.shape)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the plot using psm.effect_size_plot\n",
        "psm.effect_size_plot(save=True)\n",
        "\n",
        "# Get the current axis\n",
        "ax = plt.gca()\n",
        "\n",
        "# Customize the y-axis font size\n",
        "ax.tick_params(axis='y', labelsize=10)  # Adjust 'labelsize' to your desired font size\n",
        "\n",
        "# Save the figure if required\n",
        "plt.savefig('effect_size_plot.png')\n",
        "\n",
        "# Show the plot (optional)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import time\n",
        "# record the start time\n",
        "start_time = time.perf_counter()\n",
        "\n",
        "# Assume psm.df_matched and psm.matched_ids are already defined DataFrames\n",
        "\n",
        "# Creating dataframe for PSM matching treatment/control group users\n",
        "psm.df_matched['group'] = np.where(psm.df_matched['user_id'].isin(psm.matched_ids['user_id']), 'treatment', 'control')\n",
        "df_psm_group = psm.df_matched[['user_id', 'group']].drop_duplicates()\n",
        "\n",
        "# mapping the TOS data\n",
        "df1 = tos.copy()\n",
        "\n",
        "# Optimize by getting unique values and creating a DataFrame of all possible combinations\n",
        "all_combinations = pd.MultiIndex.from_product([df1['pt'].unique(), df_psm_group['user_id'].unique()], names=['pt', 'user_id']).to_frame(index=False)\n",
        "\n",
        "# Merge all_combinations with df1 to get the time on site data\n",
        "df3 = pd.merge(all_combinations, df1, on=['pt', 'user_id'], how='left')\n",
        "\n",
        "# Merge df3 with df_psm_group to add the group information\n",
        "df3 = pd.merge(df3, df_psm_group, on='user_id', how='left')\n",
        "\n",
        "# Fill NaN values based on column type\n",
        "df3['tos'] = df3['tos'].astype('float').fillna(0)\n",
        "\n",
        "# Release more RAM by deleting table no longer used\n",
        "# del tos\n",
        "\n",
        "# Convert 'group' to a categorical type for better memory usage and performance\n",
        "df3['group'] = df3['group'].astype('category')\n",
        "\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n"
      ],
      "metadata": {
        "id": "N2F_jRgaGcnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "\n",
        "# Winsorize the data\n",
        "df3['tos'] = winsorize(df3['tos'], limits=[0.05, 0.05])\n",
        "\n",
        "# Calculate the overall average time on site per user for each group\n",
        "overall_avg_tos = df3.groupby('group')['tos'].mean()\n",
        "\n",
        "# Calculate the absolute delta for the overall period\n",
        "overall_avg_tos['absolute_delta'] = overall_avg_tos['treatment'] - overall_avg_tos['control']\n",
        "\n",
        "# Calculate the relative delta percentage for the overall period\n",
        "overall_avg_tos['relative_delta'] = (overall_avg_tos['absolute_delta'] / overall_avg_tos['control']) * 100\n",
        "\n",
        "# Calculate the p-value for the overall period\n",
        "treatment_data = df3[df3['group'] == 'treatment']['tos']\n",
        "control_data = df3[df3['group'] == 'control']['tos']\n",
        "_, overall_p_value = ttest_ind(treatment_data, control_data, equal_var=False, nan_policy='omit')\n",
        "\n",
        "overall_avg_tos['p_value'] = overall_p_value\n",
        "\n",
        "# Calculate means and standard errors\n",
        "means = df3.groupby('group')['tos'].mean()\n",
        "std_errors = df3.groupby('group')['tos'].std() / np.sqrt(df3.groupby('group')['tos'].count())\n",
        "\n",
        "# Calculate confidence intervals for delta percentage\n",
        "confidence_level = 0.95\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "treatment_mean = means['treatment']\n",
        "treatment_se = std_errors['treatment']\n",
        "\n",
        "# Calculate the confidence interval bounds for the treatment group\n",
        "overall_avg_tos['treatment_ci_lower'] = treatment_mean - z_score * treatment_se\n",
        "overall_avg_tos['treatment_ci_upper'] = treatment_mean + z_score * treatment_se\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"Overall Metrics:\")\n",
        "print(overall_avg_tos)\n",
        "\n",
        "# Plotting (for each day if needed for comparison)\n",
        "daily_avg_tos = df3.groupby(['pt', 'group'])['tos'].mean().unstack()\n",
        "\n",
        "# Calculate the absolute delta\n",
        "daily_avg_tos['absolute_delta'] = daily_avg_tos['treatment'] - daily_avg_tos['control']\n",
        "\n",
        "# Calculate the relative delta percentage\n",
        "daily_avg_tos['relative_delta'] = (daily_avg_tos['absolute_delta'] / daily_avg_tos['control']) * 100\n",
        "\n",
        "# Calculate means and standard errors for daily data\n",
        "means = daily_avg_tos.mean()\n",
        "std_errors = daily_avg_tos.std() / np.sqrt(daily_avg_tos.count())\n",
        "\n",
        "# Calculate confidence intervals for delta percentage for daily data\n",
        "daily_avg_tos['treatment_ci'] = z_score * (std_errors['treatment'] / means['treatment']) * 100\n",
        "daily_avg_tos['control_ci'] = z_score * (std_errors['control'] / means['control']) * 100\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot delta percentage\n",
        "plt.plot(daily_avg_tos.index, daily_avg_tos['relative_delta'], label='Relative Delta Percentage (Treatment - Control)', color='blue', marker='o')\n",
        "\n",
        "# Plot confidence interval\n",
        "plt.fill_between(daily_avg_tos.index, daily_avg_tos['relative_delta'] - daily_avg_tos['treatment_ci'], daily_avg_tos['relative_delta'] + daily_avg_tos['treatment_ci'],\n",
        "                 color='gray', alpha=0.2, label='95% CI (Treatment)')\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Delta Percentage in Time on Site per User')\n",
        "plt.title('Daily Delta Percentage in Time on Site per User between Treatment and Control Groups')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the daily metrics\n",
        "display(daily_avg_tos)\n"
      ],
      "metadata": {
        "id": "FeczOKpL76Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments"
      ],
      "metadata": {
        "id": "16pifaJjGDHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "with u as (\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `data-prod-165221.ds_v2_gold_tables.wjfeng_tmp_20240329_bets_chat_channels_holdout_exposed_users_step4`\n",
        "  WHERE\n",
        "    1=1\n",
        "    AND user_logged_in = 1\n",
        "    AND app_install = 1\n",
        "    AND (ios_l1 > 0\n",
        "      OR android_l1 > 0)\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  date(pt) pt,\n",
        "  user_id,\n",
        "  sum(comments) comments,\n",
        "  sum(posts) posts\n",
        "FROM\n",
        "  `data-prod-165221.all_reddit.user_daily_votes_comments_posts`\n",
        "WHERE\n",
        "  date(pt) >= '2024-03-29' and date(pt) <= '2024-03-29' + 14\n",
        "  and user_id in (select user_id from u)\n",
        "group by 1,2\n",
        "'''\n",
        "\n",
        "comments_posts = client.query(sql).to_dataframe()"
      ],
      "metadata": {
        "id": "uJbsAWNX9Bt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# mapping the comments data\n",
        "df1 = comments_posts.copy()\n",
        "\n",
        "\n",
        "# Optimize by getting unique values and creating a DataFrame of all possible combinations\n",
        "all_combinations = pd.MultiIndex.from_product([df1['pt'].unique(), df_psm_group['user_id'].unique()], names=['pt', 'user_id']).to_frame(index=False)\n",
        "\n",
        "\n",
        "# Merge all_combinations with df1 to get the Comments data\n",
        "df3 = pd.merge(all_combinations, df1, on=['pt', 'user_id'], how='left')\n",
        "\n",
        "\n",
        "# Merge df3 with df_psm_group to add the group information\n",
        "df3 = pd.merge(df3, df_psm_group, on='user_id', how='left')\n",
        "\n",
        "\n",
        "# Fill NaN values based on column type\n",
        "df3['comments'] = df3['comments'].astype('float').fillna(0)\n",
        "\n",
        "\n",
        "# Release more RAM by deleting table no longer used\n",
        "# del comments\n",
        "\n",
        "\n",
        "# Convert 'group' to a categorical type for better memory usage and performance\n",
        "df3['group'] = df3['group'].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Winsorize the data\n",
        "# df3['comments'] = winsorize(df3['comments'], limits=[0.05, 0.05])\n",
        "\n",
        "\n",
        "# Calculate the overall average Comments per user for each group\n",
        "overall_avg_comments = df3.groupby('group')['comments'].mean()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta for the overall period\n",
        "overall_avg_comments['absolute_delta'] = overall_avg_comments['treatment'] - overall_avg_comments['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage for the overall period\n",
        "overall_avg_comments['relative_delta'] = (overall_avg_comments['absolute_delta'] / overall_avg_comments['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate the p-value for the overall period\n",
        "treatment_data = df3[df3['group'] == 'treatment']['comments']\n",
        "control_data = df3[df3['group'] == 'control']['comments']\n",
        "_, overall_p_value = ttest_ind(treatment_data, control_data, equal_var=False, nan_policy='omit')\n",
        "\n",
        "\n",
        "overall_avg_comments['p_value'] = overall_p_value\n",
        "\n",
        "\n",
        "# Calculate means and standard errors\n",
        "means = df3.groupby('group')['comments'].mean()\n",
        "std_errors = df3.groupby('group')['comments'].std() / np.sqrt(df3.groupby('group')['comments'].count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage\n",
        "confidence_level = 0.95\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "treatment_mean = means['treatment']\n",
        "treatment_se = std_errors['treatment']\n",
        "\n",
        "\n",
        "# Calculate the confidence interval bounds for the treatment group\n",
        "overall_avg_comments['treatment_ci_lower'] = treatment_mean - z_score * treatment_se\n",
        "overall_avg_comments['treatment_ci_upper'] = treatment_mean + z_score * treatment_se\n",
        "\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"Overall Metrics:\")\n",
        "print(overall_avg_comments)\n",
        "\n",
        "\n",
        "# Plotting (for each day if needed for comparison)\n",
        "daily_avg_comments = df3.groupby(['pt', 'group'])['comments'].mean().unstack()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta\n",
        "daily_avg_comments['absolute_delta'] = daily_avg_comments['treatment'] - daily_avg_comments['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage\n",
        "daily_avg_comments['relative_delta'] = (daily_avg_comments['absolute_delta'] / daily_avg_comments['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate means and standard errors for daily data\n",
        "means = daily_avg_comments.mean()\n",
        "std_errors = daily_avg_comments.std() / np.sqrt(daily_avg_comments.count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage for daily data\n",
        "daily_avg_comments['treatment_ci'] = z_score * (std_errors['treatment'] / means['treatment']) * 100\n",
        "daily_avg_comments['control_ci'] = z_score * (std_errors['control'] / means['control']) * 100\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "# Plot delta percentage\n",
        "plt.plot(daily_avg_comments.index, daily_avg_comments['relative_delta'], label='Relative Delta Percentage (Treatment - Control)', color='blue', marker='o')\n",
        "\n",
        "\n",
        "# Plot confidence interval\n",
        "plt.fill_between(daily_avg_comments.index, daily_avg_comments['relative_delta'] - daily_avg_comments['treatment_ci'], daily_avg_comments['relative_delta'] + daily_avg_comments['treatment_ci'],\n",
        "                color='gray', alpha=0.2, label='95% CI (Treatment)')\n",
        "\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Delta Percentage in Comments per User')\n",
        "plt.title('Daily Delta Percentage in Comments per User between Treatment and Control Groups')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Display the daily metrics\n",
        "display(daily_avg_comments)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qe2xVaf8GCbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I0Kv920SGCdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post"
      ],
      "metadata": {
        "id": "qNpasyvlH0UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping the posts data\n",
        "df1 = comments_posts.copy()\n",
        "\n",
        "# Optimize by getting unique values and creating a DataFrame of all possible combinations\n",
        "all_combinations = pd.MultiIndex.from_product([df1['pt'].unique(), df_psm_group['user_id'].unique()], names=['pt', 'user_id']).to_frame(index=False)\n",
        "\n",
        "# Merge all_combinations with df1 to get the posts data\n",
        "df3 = pd.merge(all_combinations, df1, on=['pt', 'user_id'], how='left')\n",
        "\n",
        "# Merge df3 with df_psm_group to add the group information\n",
        "df3 = pd.merge(df3, df_psm_group, on='user_id', how='left')\n",
        "\n",
        "# Fill NaN values based on column type\n",
        "df3['posts'] = df3['posts'].astype('float').fillna(0)\n",
        "\n",
        "# Release more RAM by deleting table no longer used\n",
        "# del posts\n",
        "\n",
        "# Convert 'group' to a categorical type for better memory usage and performance\n",
        "df3['group'] = df3['group'].astype('category')\n",
        "\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "from IPython.display import display\n",
        "\n",
        "# Winsorize the data\n",
        "# df3['posts'] = winsorize(df3['posts'], limits=[0.05, 0.05])\n",
        "\n",
        "# Calculate the overall average posts per user for each group\n",
        "overall_avg_posts = df3.groupby('group')['posts'].mean()\n",
        "\n",
        "# Calculate the absolute delta for the overall period\n",
        "overall_avg_posts['absolute_delta'] = overall_avg_posts['treatment'] - overall_avg_posts['control']\n",
        "\n",
        "# Calculate the relative delta percentage for the overall period\n",
        "overall_avg_posts['relative_delta'] = (overall_avg_posts['absolute_delta'] / overall_avg_posts['control']) * 100\n",
        "\n",
        "# Calculate the p-value for the overall period\n",
        "treatment_data = df3[df3['group'] == 'treatment']['posts']\n",
        "control_data = df3[df3['group'] == 'control']['posts']\n",
        "_, overall_p_value = ttest_ind(treatment_data, control_data, equal_var=False, nan_policy='omit')\n",
        "\n",
        "overall_avg_posts['p_value'] = overall_p_value\n",
        "\n",
        "# Calculate means and standard errors\n",
        "means = df3.groupby('group')['posts'].mean()\n",
        "std_errors = df3.groupby('group')['posts'].std() / np.sqrt(df3.groupby('group')['posts'].count())\n",
        "\n",
        "# Calculate confidence intervals for delta percentage\n",
        "confidence_level = 0.95\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "treatment_mean = means['treatment']\n",
        "treatment_se = std_errors['treatment']\n",
        "\n",
        "# Calculate the confidence interval bounds for the treatment group\n",
        "overall_avg_posts['treatment_ci_lower'] = treatment_mean - z_score * treatment_se\n",
        "overall_avg_posts['treatment_ci_upper'] = treatment_mean + z_score * treatment_se\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"Overall Metrics:\")\n",
        "print(overall_avg_posts)\n",
        "\n",
        "# Plotting (for each day if needed for comparison)\n",
        "daily_avg_posts = df3.groupby(['pt', 'group'])['posts'].mean().unstack()\n",
        "\n",
        "# Calculate the absolute delta\n",
        "daily_avg_posts['absolute_delta'] = daily_avg_posts['treatment'] - daily_avg_posts['control']\n",
        "\n",
        "# Calculate the relative delta percentage\n",
        "daily_avg_posts['relative_delta'] = (daily_avg_posts['absolute_delta'] / daily_avg_posts['control']) * 100\n",
        "\n",
        "# Calculate means and standard errors for daily data\n",
        "means = daily_avg_posts.mean()\n",
        "std_errors = daily_avg_posts.std() / np.sqrt(daily_avg_posts.count())\n",
        "\n",
        "# Calculate confidence intervals for delta percentage for daily data\n",
        "daily_avg_posts['treatment_ci'] = z_score * (std_errors['treatment'] / means['treatment']) * 100\n",
        "daily_avg_posts['control_ci'] = z_score * (std_errors['control'] / means['control']) * 100\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot delta percentage\n",
        "plt.plot(daily_avg_posts.index, daily_avg_posts['relative_delta'], label='Relative Delta Percentage (Treatment - Control)', color='blue', marker='o')\n",
        "\n",
        "# Plot confidence interval\n",
        "plt.fill_between(daily_avg_posts.index, daily_avg_posts['relative_delta'] - daily_avg_posts['treatment_ci'], daily_avg_posts['relative_delta'] + daily_avg_posts['treatment_ci'],\n",
        "               color='gray', alpha=0.2, label='95% CI (Treatment)')\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Delta Percentage in posts per User')\n",
        "plt.title('Daily Delta Percentage in posts per User between Treatment and Control Groups')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the daily metrics\n",
        "display(daily_avg_posts)"
      ],
      "metadata": {
        "id": "ZlAeiUDUGCfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql = '''\n",
        "with u as (\n",
        "  SELECT\n",
        "    *\n",
        "  FROM\n",
        "    `data-prod-165221.ds_v2_gold_tables.wjfeng_tmp_20240329_bets_chat_channels_holdout_exposed_users_step4`\n",
        "  WHERE\n",
        "    1=1\n",
        "    AND user_logged_in = 1\n",
        "    AND app_install = 1\n",
        "    AND (ios_l1 > 0\n",
        "      OR android_l1 > 0)\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  date(pt) pt,\n",
        "  user_id,\n",
        "  sum(comments_consumed) comments_consumed,\n",
        "  sum(posts_consumed) posts_consumed\n",
        "FROM\n",
        "  `data-prod-165221.growth_team_tables.user_post_comment_consume_attributes_agg`\n",
        "WHERE\n",
        "  date(pt) >= '2024-03-29' and date(pt) <= '2024-03-29' + 14\n",
        "  and user_id in (select user_id from u)\n",
        "group by 1,2\n",
        "'''\n",
        "\n",
        "cp_consumed = client.query(sql).to_dataframe()"
      ],
      "metadata": {
        "id": "d08LZWoSGCiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comments / Post consumed"
      ],
      "metadata": {
        "id": "H1LvWLULKf2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping the comments_consumed data\n",
        "df1 = cp_consumed.copy()\n",
        "\n",
        "\n",
        "# Optimize by getting unique values and creating a DataFrame of all possible combinations\n",
        "all_combinations = pd.MultiIndex.from_product([df1['pt'].unique(), df_psm_group['user_id'].unique()], names=['pt', 'user_id']).to_frame(index=False)\n",
        "\n",
        "\n",
        "# Merge all_combinations with df1 to get the comments_consumed data\n",
        "df3 = pd.merge(all_combinations, df1, on=['pt', 'user_id'], how='left')\n",
        "\n",
        "\n",
        "# Merge df3 with df_psm_group to add the group information\n",
        "df3 = pd.merge(df3, df_psm_group, on='user_id', how='left')\n",
        "\n",
        "\n",
        "# Fill NaN values based on column type\n",
        "df3['comments_consumed'] = df3['comments_consumed'].astype('float').fillna(0)\n",
        "\n",
        "\n",
        "# Release more RAM by deleting table no longer used\n",
        "# del comments_consumed\n",
        "\n",
        "\n",
        "# Convert 'group' to a categorical type for better memory usage and performance\n",
        "df3['group'] = df3['group'].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Winsorize the data\n",
        "# df3['comments_consumed'] = winsorize(df3['comments_consumed'], limits=[0.05, 0.05])\n",
        "\n",
        "\n",
        "# Calculate the overall average comments_consumed per user for each group\n",
        "overall_avg_comments_consumed = df3.groupby('group')['comments_consumed'].mean()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta for the overall period\n",
        "overall_avg_comments_consumed['absolute_delta'] = overall_avg_comments_consumed['treatment'] - overall_avg_comments_consumed['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage for the overall period\n",
        "overall_avg_comments_consumed['relative_delta'] = (overall_avg_comments_consumed['absolute_delta'] / overall_avg_comments_consumed['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate the p-value for the overall period\n",
        "treatment_data = df3[df3['group'] == 'treatment']['comments_consumed']\n",
        "control_data = df3[df3['group'] == 'control']['comments_consumed']\n",
        "_, overall_p_value = ttest_ind(treatment_data, control_data, equal_var=False, nan_policy='omit')\n",
        "\n",
        "\n",
        "overall_avg_comments_consumed['p_value'] = overall_p_value\n",
        "\n",
        "\n",
        "# Calculate means and standard errors\n",
        "means = df3.groupby('group')['comments_consumed'].mean()\n",
        "std_errors = df3.groupby('group')['comments_consumed'].std() / np.sqrt(df3.groupby('group')['comments_consumed'].count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage\n",
        "confidence_level = 0.95\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "treatment_mean = means['treatment']\n",
        "treatment_se = std_errors['treatment']\n",
        "\n",
        "\n",
        "# Calculate the confidence interval bounds for the treatment group\n",
        "overall_avg_comments_consumed['treatment_ci_lower'] = treatment_mean - z_score * treatment_se\n",
        "overall_avg_comments_consumed['treatment_ci_upper'] = treatment_mean + z_score * treatment_se\n",
        "\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"Overall Metrics:\")\n",
        "print(overall_avg_comments_consumed)\n",
        "\n",
        "\n",
        "# Plotting (for each day if needed for comparison)\n",
        "daily_avg_comments_consumed = df3.groupby(['pt', 'group'])['comments_consumed'].mean().unstack()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta\n",
        "daily_avg_comments_consumed['absolute_delta'] = daily_avg_comments_consumed['treatment'] - daily_avg_comments_consumed['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage\n",
        "daily_avg_comments_consumed['relative_delta'] = (daily_avg_comments_consumed['absolute_delta'] / daily_avg_comments_consumed['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate means and standard errors for daily data\n",
        "means = daily_avg_comments_consumed.mean()\n",
        "std_errors = daily_avg_comments_consumed.std() / np.sqrt(daily_avg_comments_consumed.count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage for daily data\n",
        "daily_avg_comments_consumed['treatment_ci'] = z_score * (std_errors['treatment'] / means['treatment']) * 100\n",
        "daily_avg_comments_consumed['control_ci'] = z_score * (std_errors['control'] / means['control']) * 100\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "# Plot delta percentage\n",
        "plt.plot(daily_avg_comments_consumed.index, daily_avg_comments_consumed['relative_delta'], label='Relative Delta Percentage (Treatment - Control)', color='blue', marker='o')\n",
        "\n",
        "\n",
        "# Plot confidence interval\n",
        "plt.fill_between(daily_avg_comments_consumed.index, daily_avg_comments_consumed['relative_delta'] - daily_avg_comments_consumed['treatment_ci'], daily_avg_comments_consumed['relative_delta'] + daily_avg_comments_consumed['treatment_ci'],\n",
        "              color='gray', alpha=0.2, label='95% CI (Treatment)')\n",
        "\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Delta Percentage in comments_consumed per User')\n",
        "plt.title('Daily Delta Percentage in comments_consumed per User between Treatment and Control Groups')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Display the daily metrics\n",
        "display(daily_avg_comments_consumed)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y5pHjaPzGCkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# posts consumed"
      ],
      "metadata": {
        "id": "HEYH2kYJNQg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping the posts_consumed data\n",
        "df1 = cp_consumed.copy()\n",
        "\n",
        "\n",
        "# Optimize by getting unique values and creating a DataFrame of all possible combinations\n",
        "all_combinations = pd.MultiIndex.from_product([df1['pt'].unique(), df_psm_group['user_id'].unique()], names=['pt', 'user_id']).to_frame(index=False)\n",
        "\n",
        "\n",
        "# Merge all_combinations with df1 to get the posts_consumed data\n",
        "df3 = pd.merge(all_combinations, df1, on=['pt', 'user_id'], how='left')\n",
        "\n",
        "\n",
        "# Merge df3 with df_psm_group to add the group information\n",
        "df3 = pd.merge(df3, df_psm_group, on='user_id', how='left')\n",
        "\n",
        "\n",
        "# Fill NaN values based on column type\n",
        "df3['posts_consumed'] = df3['posts_consumed'].astype('float').fillna(0)\n",
        "\n",
        "\n",
        "# Release more RAM by deleting table no longer used\n",
        "# del posts_consumed\n",
        "\n",
        "\n",
        "# Convert 'group' to a categorical type for better memory usage and performance\n",
        "df3['group'] = df3['group'].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# record the end time\n",
        "end_time = time.perf_counter()\n",
        "# calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time: {elapsed_time:.6f} seconds\")\n",
        "\n",
        "\n",
        "## --------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Winsorize the data\n",
        "# df3['posts_consumed'] = winsorize(df3['posts_consumed'], limits=[0.05, 0.05])\n",
        "\n",
        "\n",
        "# Calculate the overall average posts_consumed per user for each group\n",
        "overall_avg_posts_consumed = df3.groupby('group')['posts_consumed'].mean()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta for the overall period\n",
        "overall_avg_posts_consumed['absolute_delta'] = overall_avg_posts_consumed['treatment'] - overall_avg_posts_consumed['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage for the overall period\n",
        "overall_avg_posts_consumed['relative_delta'] = (overall_avg_posts_consumed['absolute_delta'] / overall_avg_posts_consumed['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate the p-value for the overall period\n",
        "treatment_data = df3[df3['group'] == 'treatment']['posts_consumed']\n",
        "control_data = df3[df3['group'] == 'control']['posts_consumed']\n",
        "_, overall_p_value = ttest_ind(treatment_data, control_data, equal_var=False, nan_policy='omit')\n",
        "\n",
        "\n",
        "overall_avg_posts_consumed['p_value'] = overall_p_value\n",
        "\n",
        "\n",
        "# Calculate means and standard errors\n",
        "means = df3.groupby('group')['posts_consumed'].mean()\n",
        "std_errors = df3.groupby('group')['posts_consumed'].std() / np.sqrt(df3.groupby('group')['posts_consumed'].count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage\n",
        "confidence_level = 0.95\n",
        "z_score = norm.ppf((1 + confidence_level) / 2)\n",
        "treatment_mean = means['treatment']\n",
        "treatment_se = std_errors['treatment']\n",
        "\n",
        "\n",
        "# Calculate the confidence interval bounds for the treatment group\n",
        "overall_avg_posts_consumed['treatment_ci_lower'] = treatment_mean - z_score * treatment_se\n",
        "overall_avg_posts_consumed['treatment_ci_upper'] = treatment_mean + z_score * treatment_se\n",
        "\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"Overall Metrics:\")\n",
        "print(overall_avg_posts_consumed)\n",
        "\n",
        "\n",
        "# Plotting (for each day if needed for comparison)\n",
        "daily_avg_posts_consumed = df3.groupby(['pt', 'group'])['posts_consumed'].mean().unstack()\n",
        "\n",
        "\n",
        "# Calculate the absolute delta\n",
        "daily_avg_posts_consumed['absolute_delta'] = daily_avg_posts_consumed['treatment'] - daily_avg_posts_consumed['control']\n",
        "\n",
        "\n",
        "# Calculate the relative delta percentage\n",
        "daily_avg_posts_consumed['relative_delta'] = (daily_avg_posts_consumed['absolute_delta'] / daily_avg_posts_consumed['control']) * 100\n",
        "\n",
        "\n",
        "# Calculate means and standard errors for daily data\n",
        "means = daily_avg_posts_consumed.mean()\n",
        "std_errors = daily_avg_posts_consumed.std() / np.sqrt(daily_avg_posts_consumed.count())\n",
        "\n",
        "\n",
        "# Calculate confidence intervals for delta percentage for daily data\n",
        "daily_avg_posts_consumed['treatment_ci'] = z_score * (std_errors['treatment'] / means['treatment']) * 100\n",
        "daily_avg_posts_consumed['control_ci'] = z_score * (std_errors['control'] / means['control']) * 100\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "\n",
        "# Plot delta percentage\n",
        "plt.plot(daily_avg_posts_consumed.index, daily_avg_posts_consumed['relative_delta'], label='Relative Delta Percentage (Treatment - Control)', color='blue', marker='o')\n",
        "\n",
        "\n",
        "# Plot confidence interval\n",
        "plt.fill_between(daily_avg_posts_consumed.index, daily_avg_posts_consumed['relative_delta'] - daily_avg_posts_consumed['treatment_ci'], daily_avg_posts_consumed['relative_delta'] + daily_avg_posts_consumed['treatment_ci'],\n",
        "              color='gray', alpha=0.2, label='95% CI (Treatment)')\n",
        "\n",
        "\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Delta Percentage in posts_consumed per User')\n",
        "plt.title('Daily Delta Percentage in posts_consumed per User between Treatment and Control Groups')\n",
        "plt.legend()\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Display the daily metrics\n",
        "display(daily_avg_posts_consumed)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LnSKDKXvGCms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqN56RhuNTCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}